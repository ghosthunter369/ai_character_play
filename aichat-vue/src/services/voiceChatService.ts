interface VADResult {
  shouldSend: boolean
  shouldStop: boolean
  volume: number
  status: 'silence' | 'speech' | 'waiting'
  info: string
}

interface VoiceChatMessage {
  type: 'user' | 'ai'
  content: string
  timestamp: number
  audioUrl?: string
}

class VoiceChatService {
  private websocket: WebSocket | null = null
  private audioContext: AudioContext | null = null
  private mediaStream: MediaStream | null = null
  private processor: ScriptProcessorNode | null = null
  private source: MediaStreamAudioSourceNode | null = null
  private isRecording = false
  private isConnected = false
  private audioBuffer = new Float32Array(0)
  private playbackQueue: ArrayBuffer[] = []
  private isPlaying = false
  
  // VADç›¸å…³çŠ¶æ€
  private vadState: 'silence' | 'speech' | 'waiting' = 'silence'
  private speechStartTime: number | null = null
  private silenceStartTime: number | null = null
  private currentVolume = 0
  private volumeHistory: number[] = []
  private hasDetectedSpeech = false

  // æ™ºèƒ½æ–­å¥çŠ¶æ€
  private currentSentence = ''
  private lastPartialResult = ''
  private sentenceEndTimer: NodeJS.Timeout | null = null

  // ç»Ÿè®¡ä¿¡æ¯
  private frameCount = 0
  private silentFrameCount = 0
  private speechFrameCount = 0

  // æµå¼AIå›å¤ç›¸å…³
  private currentStreamingMessage: {
    id: string
    content: string
    timestamp: number
    isComplete: boolean
  } | null = null
  private streamingTimer: NodeJS.Timeout | null = null

  // å›è°ƒå‡½æ•°
  public onMessage?: (message: VoiceChatMessage) => void
  public onStreamingMessage?: (message: VoiceChatMessage & { isStreaming: boolean }) => void
  public onConnectionChange?: (connected: boolean) => void
  public onVolumeChange?: (volume: number, status: string, info: string) => void
  public onSilenceDetected?: () => void
  public onAsrPartial?: (text: string) => void  // æ–°å¢ï¼šå¤„ç†partial ASRç»“æœ
  public onAsrFinal?: (text: string) => void    // æ–°å¢ï¼šå¤„ç†final ASRç»“æœ

  async connect(appId: string | number): Promise<void> {
    if (this.isConnected) return

    try {
      // å»ºç«‹WebSocketè¿æ¥ - ä½¿ç”¨æ­£ç¡®çš„ç«¯å£å’Œè·¯å¾„
      const wsUrl = `ws://localhost:8123/api/ws/audio?appId=${appId}`
      console.log('ğŸ”— æ­£åœ¨è¿æ¥WebSocket:', wsUrl)
      this.websocket = new WebSocket(wsUrl)

      this.websocket.onopen = () => {
        console.log('âœ… WebSocketè¿æ¥å·²å»ºç«‹')
        this.isConnected = true
        this.onConnectionChange?.(true)
      }

      this.websocket.onmessage = (event) => {
        this.handleWebSocketMessage(event)
      }

      this.websocket.onclose = () => {
        console.log('âŒ WebSocketè¿æ¥å·²å…³é—­')
        this.isConnected = false
        this.onConnectionChange?.(false)
      }

      this.websocket.onerror = (error) => {
        console.error('âŒ WebSocketé”™è¯¯:', error)
        this.isConnected = false
        this.onConnectionChange?.(false)
      }

      // ç­‰å¾…è¿æ¥å»ºç«‹
      await new Promise((resolve, reject) => {
        const timeout = setTimeout(() => reject(new Error('è¿æ¥è¶…æ—¶')), 5000)
        this.websocket!.onopen = () => {
          clearTimeout(timeout)
          this.isConnected = true
          this.onConnectionChange?.(true)
          console.log('âœ… WebSocketè¿æ¥æˆåŠŸå»ºç«‹')
          resolve(void 0)
        }
        this.websocket!.onerror = () => {
          clearTimeout(timeout)
          reject(new Error('è¿æ¥å¤±è´¥'))
        }
      })

    } catch (error) {
      console.error('âŒ è¿æ¥å¤±è´¥:', error)
      throw error
    }
  }

  async disconnect(): Promise<void> {
    console.log('ğŸ”Œ å¼€å§‹æ–­å¼€è¿æ¥...')
    
    if (this.isRecording) {
      await this.stopRecording()
    }

    if (this.websocket) {
      this.websocket.close()
      this.websocket = null
    }

    this.isConnected = false
    this.onConnectionChange?.(false)
    console.log('âœ… è¿æ¥å·²æ–­å¼€')
  }

  async startRecording(): Promise<void> {
    if (this.isRecording) return

    try {
      console.log('ğŸ¤ å¼€å§‹å¯åŠ¨å½•éŸ³...')
      
      // è·å–éº¦å…‹é£æƒé™
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      this.audioContext = new AudioContext({ sampleRate: 16000 })
      this.source = this.audioContext.createMediaStreamSource(this.mediaStream)
      
      // åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨
      const bufferSize = 4096
      const frameSize = 1024 // æ¯å¸§1024ä¸ªæ ·æœ¬ï¼Œçº¦64ms
      this.processor = this.audioContext.createScriptProcessor(bufferSize, 1, 1)

      // é‡ç½®VADçŠ¶æ€å’Œç»Ÿè®¡
      this.vadState = 'silence'
      this.speechStartTime = null
      this.silenceStartTime = null
      this.hasDetectedSpeech = false
      this.audioBuffer = new Float32Array(0)
      this.frameCount = 0
      this.silentFrameCount = 0
      this.speechFrameCount = 0

      console.log('ğŸµ éŸ³é¢‘å¤„ç†å™¨é…ç½®å®Œæˆï¼Œå¼€å§‹å¤„ç†éŸ³é¢‘æµ...')

      this.processor.onaudioprocess = (event) => {
        if (!this.isRecording) return

        const inputBuffer = event.inputBuffer
        const inputData = inputBuffer.getChannelData(0)

        // æ™ºèƒ½è¯­éŸ³æ´»åŠ¨æ£€æµ‹
        const vadResult = this.processVAD(inputData)

        // æ›´æ–°éŸ³é‡æŒ‡ç¤ºå™¨
        this.onVolumeChange?.(vadResult.volume, vadResult.status, vadResult.info)

        // ç´¯ç§¯éŸ³é¢‘æ•°æ® - åªåœ¨æœ‰è¯­éŸ³æˆ–åˆšå¼€å§‹é™éŸ³æ—¶å‘é€
        const shouldSendAudio = vadResult.status === 'speech' || 
                               (vadResult.status === 'silence' && this.hasDetectedSpeech)

        if (shouldSendAudio) {
          const newBuffer = new Float32Array(this.audioBuffer.length + inputData.length)
          newBuffer.set(this.audioBuffer)
          newBuffer.set(inputData, this.audioBuffer.length)
          this.audioBuffer = newBuffer

          // æŒ‰å›ºå®šå¸§å¤§å°å‘é€
          while (this.audioBuffer.length >= frameSize) {
            const frameData = this.audioBuffer.slice(0, frameSize)
            this.audioBuffer = this.audioBuffer.slice(frameSize)

            // ä¼˜åŒ–çš„16ä½PCMè½¬æ¢
            const pcmData = new Int16Array(frameSize)
            for (let i = 0; i < frameSize; i++) {
              const sample = Math.max(-1, Math.min(1, frameData[i]))
              pcmData[i] = sample < 0 ? Math.round(sample * 32768) : Math.round(sample * 32767)
            }

            const frameType = vadResult.status === 'silence' ? 'é™éŸ³å¸§' : 'è¯­éŸ³å¸§'
            this.frameCount++
            
            if (vadResult.status === 'silence') {
              this.silentFrameCount++
            } else {
              this.speechFrameCount++
            }
            
            if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
              this.websocket.send(pcmData.buffer)
              console.log(`ğŸµ å‘é€${frameType}: éŸ³é‡:${vadResult.volume.toFixed(4)}, çŠ¶æ€:${vadResult.status}`)
            }
          }
        }

        // æ£€æŸ¥æ˜¯å¦éœ€è¦å‘é€æ®µè½ç»“æŸä¿¡å·
        if (vadResult.shouldStop && this.hasDetectedSpeech) {
          this.sendSegmentEnd()
        }
      }

      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      this.source.connect(this.processor)
      this.processor.connect(this.audioContext.destination)

      this.isRecording = true
      console.log('âœ… å½•éŸ³å·²å¯åŠ¨ï¼Œå¼€å§‹æŒç»­æ¨æµ')

    } catch (error) {
      console.error('âŒ å¯åŠ¨å½•éŸ³å¤±è´¥:', error)
      throw error
    }
  }

  async stopRecording(): Promise<void> {
    if (!this.isRecording) return

    console.log('ğŸ›‘ åœæ­¢å½•éŸ³...')
    this.isRecording = false

    // å‘é€å‰©ä½™çš„éŸ³é¢‘æ•°æ®
    if (this.audioBuffer.length > 0 && this.websocket && this.websocket.readyState === WebSocket.OPEN) {
      const pcmData = new Int16Array(this.audioBuffer.length)
      for (let i = 0; i < this.audioBuffer.length; i++) {
        const sample = Math.max(-1, Math.min(1, this.audioBuffer[i]))
        pcmData[i] = sample < 0 ? Math.round(sample * 32768) : Math.round(sample * 32767)
      }
      this.websocket.send(pcmData.buffer)
      console.log('ğŸ“¤ å‘é€å‰©ä½™éŸ³é¢‘æ•°æ®:', pcmData.buffer.byteLength, 'å­—èŠ‚')
    }

    // å‘é€ç»“æŸæ ‡è®°
    if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
      this.websocket.send(JSON.stringify({ type: 'end' }))
      console.log('ğŸ“¤ å‘é€å½•éŸ³ç»“æŸæ ‡è®°')
    }

    // æ¸…ç†éŸ³é¢‘èµ„æº
    if (this.processor) {
      this.processor.disconnect()
      this.processor = null
    }

    if (this.source) {
      this.source.disconnect()
      this.source = null
    }

    if (this.audioContext) {
      await this.audioContext.close()
      this.audioContext = null
    }

    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach(track => track.stop())
      this.mediaStream = null
    }

    this.audioBuffer = new Float32Array(0)
    
    // è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    console.log('ğŸ“Š å½•éŸ³ä¼šè¯ç»Ÿè®¡:')
    console.log(`   æ€»å¸§æ•°: ${this.frameCount}`)
    console.log(`   é™éŸ³å¸§: ${this.silentFrameCount} (${((this.silentFrameCount/this.frameCount)*100).toFixed(1)}%)`)
    console.log(`   è¯­éŸ³å¸§: ${this.speechFrameCount} (${((this.speechFrameCount/this.frameCount)*100).toFixed(1)}%)`)
    console.log('âœ… å½•éŸ³å·²åœæ­¢')
  }

  private processVAD(audioData: Float32Array): VADResult {
    // è®¡ç®—éŸ³é‡
    let sum = 0
    for (let i = 0; i < audioData.length; i++) {
      sum += audioData[i] * audioData[i]
    }
    const rms = Math.sqrt(sum / audioData.length)
    this.currentVolume = rms

    // æ›´æ–°éŸ³é‡å†å²
    this.volumeHistory.push(rms)
    if (this.volumeHistory.length > 10) {
      this.volumeHistory.shift()
    }

    // åŠ¨æ€é˜ˆå€¼
    const avgVolume = this.volumeHistory.reduce((a, b) => a + b, 0) / this.volumeHistory.length
    const speechThreshold = Math.max(0.01, avgVolume * 2)
    const silenceThreshold = speechThreshold * 0.3

    // é…ç½®å‚æ•°
    const maxSilenceDuration = 1500 // 1.5ç§’é™éŸ³åå‘é€æ®µè½ç»“æŸ
    const minSpeechDuration = 500   // æœ€å°‘500msè¯­éŸ³æ‰ç®—æœ‰æ•ˆ
    const segmentEndDelay = 800     // æ®µè½ç»“æŸå»¶è¿Ÿï¼Œç­‰å¾…å¯èƒ½çš„ç»§ç»­è¯´è¯

    const currentTime = Date.now()
    let shouldSend = true
    let shouldStop = false
    let statusInfo = ''

    // çŠ¶æ€æœºå¤„ç† - æ™ºèƒ½æ–­å¥æ£€æµ‹
    switch (this.vadState) {
      case 'silence':
        if (this.currentVolume > speechThreshold) {
          this.vadState = 'speech'
          this.speechStartTime = currentTime
          this.silenceStartTime = null
          this.hasDetectedSpeech = true

          statusInfo = 'æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹'
          console.log('ğŸ¤ VADçŠ¶æ€å˜æ›´: silence -> speech')
          
          // æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ®µè½ç»“æŸå®šæ—¶å™¨
          if (this.sentenceEndTimer) {
            clearTimeout(this.sentenceEndTimer)
            this.sentenceEndTimer = null
          }
        } else {
          statusInfo = this.hasDetectedSpeech ? 'ç­‰å¾…ä¸‹ä¸€å¥è¯...' : 'ç­‰å¾…è¯­éŸ³è¾“å…¥'
          shouldSend = false // çº¯é™éŸ³æ—¶ä¸å‘é€éŸ³é¢‘
        }
        break

      case 'speech':
        if (this.currentVolume > silenceThreshold) {
          const speechDuration = currentTime - (this.speechStartTime || 0)
          statusInfo = `è¯­éŸ³è¿›è¡Œä¸­ (${Math.round(speechDuration / 100) / 10}s)`
          
          // æ¸…é™¤æ®µè½ç»“æŸå®šæ—¶å™¨ï¼ˆç»§ç»­è¯´è¯ï¼‰
          if (this.sentenceEndTimer) {
            clearTimeout(this.sentenceEndTimer)
            this.sentenceEndTimer = null
          }
        } else {
          if (!this.silenceStartTime) {
            this.silenceStartTime = currentTime
            console.log('ğŸ”‡ æ£€æµ‹åˆ°è¯­éŸ³è½¬é™éŸ³ï¼Œå¼€å§‹é™éŸ³è®¡æ—¶')
          }

          const speechDuration = currentTime - (this.speechStartTime || 0)
          const silenceDuration = currentTime - this.silenceStartTime

          if (speechDuration >= minSpeechDuration && silenceDuration >= maxSilenceDuration) {
            // è®¾ç½®æ®µè½ç»“æŸå®šæ—¶å™¨ï¼Œå»¶è¿Ÿå‘é€ä»¥é˜²ç”¨æˆ·ç»§ç»­è¯´è¯
            if (!this.sentenceEndTimer) {
              this.sentenceEndTimer = setTimeout(() => {
                console.log('â° æ®µè½ç»“æŸå®šæ—¶å™¨è§¦å‘ï¼Œå‘é€æ®µè½ç»“æŸä¿¡å·')
                shouldStop = true
                this.vadState = 'waiting' // ç­‰å¾…AIå›å¤
                this.speechStartTime = null
                this.silenceStartTime = null
              }, segmentEndDelay)
            }
            statusInfo = `è¯­éŸ³æ®µå³å°†ç»“æŸ (é™éŸ³${Math.round(silenceDuration / 100) / 10}s)`
          } else {
            statusInfo = `è¯­éŸ³ä¸­é™éŸ³ (${Math.round(silenceDuration / 100) / 10}s)`
          }
        }
        break

      case 'waiting':
        statusInfo = 'AIæ­£åœ¨å›å¤ä¸­...'
        shouldSend = false // AIå›å¤æ—¶ä¸å‘é€éŸ³é¢‘
        break
    }

    return {
      shouldSend,
      shouldStop,
      volume: this.currentVolume,
      status: this.vadState === 'silence' ? 'silence' : 
              this.vadState === 'speech' ? 'speech' : 'waiting',
      info: statusInfo
    }
  }

  // å‘é€æ®µè½ç»“æŸä¿¡å·
  private sendSegmentEnd(): void {
    if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
      // å‘é€æ®µè½ç»“æŸæ ‡è®°
      this.websocket.send(JSON.stringify({ type: 'segment_end' }))
      console.log('ğŸ“¤ å‘é€æ®µè½ç»“æŸä¿¡å·')
      
      // é‡ç½®çŠ¶æ€
      this.hasDetectedSpeech = false
      this.currentSentence = ''
      this.lastPartialResult = ''
      
      // æ¸…é™¤å®šæ—¶å™¨
      if (this.sentenceEndTimer) {
        clearTimeout(this.sentenceEndTimer)
        this.sentenceEndTimer = null
      }
    }
  }

  // é‡ç½®VADçŠ¶æ€ï¼ˆAIå›å¤å®Œæˆåè°ƒç”¨ï¼‰
  private resetVADState(): void {
    this.vadState = 'silence'
    this.speechStartTime = null
    this.silenceStartTime = null
    this.hasDetectedSpeech = false
    this.currentSentence = ''
    this.lastPartialResult = ''
    
    if (this.sentenceEndTimer) {
      clearTimeout(this.sentenceEndTimer)
      this.sentenceEndTimer = null
    }
    
    console.log('ğŸ”„ VADçŠ¶æ€å·²é‡ç½®ï¼Œå‡†å¤‡æ¥æ”¶æ–°çš„è¯­éŸ³è¾“å…¥')
  }

  private handleWebSocketMessage(event: MessageEvent): void {
    const timestamp = new Date().toLocaleTimeString()
    
    // æ£€æŸ¥æ¶ˆæ¯ç±»å‹
    if (event.data instanceof ArrayBuffer) {
      // å¤„ç†äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®ï¼ˆPCMæ ¼å¼ï¼‰
      console.log('ğŸ”Š æ”¶åˆ°ArrayBufferéŸ³é¢‘æ•°æ®:', {
        timestamp: timestamp,
        messageType: 'ArrayBufferéŸ³é¢‘',
        byteLength: event.data.byteLength
      })
      this.playbackQueue.push(event.data)
      this.processPlaybackQueue()
      return
    }

    // å¤„ç†Blobç±»å‹æ¶ˆæ¯
    if (event.data instanceof Blob) {
      console.log('ğŸ”Š æ”¶åˆ°BlobéŸ³é¢‘æ•°æ®:', {
        timestamp: timestamp,
        messageType: 'BlobéŸ³é¢‘',
        size: event.data.size,
        type: event.data.type
      })
      // å°†Blobè½¬æ¢ä¸ºArrayBuffer
      event.data.arrayBuffer().then(arrayBuffer => {
        this.playbackQueue.push(arrayBuffer)
        this.processPlaybackQueue()
      }).catch(error => {
        console.error('âŒ Blobâ†’ArrayBufferè½¬æ¢å¤±è´¥:', error)
      })
      return
    }

    // ç¡®ä¿æ¶ˆæ¯æ˜¯å­—ç¬¦ä¸²ç±»å‹
    if (typeof event.data !== 'string') {
      console.warn('âš ï¸ æ”¶åˆ°éå­—ç¬¦ä¸²æ¶ˆæ¯:', typeof event.data, event.data)
      return
    }

    const message = event.data
    
    // æ·»åŠ è¯¦ç»†çš„æ¶ˆæ¯è°ƒè¯•ä¿¡æ¯
    console.log('ğŸ” æ”¶åˆ°WebSocketæ¶ˆæ¯:', {
      timestamp: timestamp,
      messageType: message.startsWith('REPLY:') ? 'AIå›å¤' :
        message.startsWith('AUDIO:') ? 'TTSéŸ³é¢‘' : 'ASRè¯†åˆ«',
      messageLength: message.length,
      messagePreview: message.substring(0, 50) + (message.length > 50 ? '...' : '')
    })

    if (message.startsWith('REPLY:')) {
      // AIå›å¤æ–‡æœ¬ - å®ç°æµå¼æ‹¼æ¥æ˜¾ç¤º
      const replyText = message.substring(6)
      console.log('ğŸ“ å¤„ç†AIå›å¤ç‰‡æ®µ:', replyText)
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„å›å¤å¼€å§‹
      if (!this.currentStreamingMessage) {
        // å¼€å§‹æ–°çš„æµå¼å›å¤
        this.currentStreamingMessage = {
          id: `ai_${Date.now()}`,
          content: replyText,
          timestamp: Date.now(),
          isComplete: false
        }
        
        // ç«‹å³æ˜¾ç¤ºç¬¬ä¸€ä¸ªç‰‡æ®µ
        this.onStreamingMessage?.({
          type: 'ai',
          content: this.currentStreamingMessage.content,
          timestamp: this.currentStreamingMessage.timestamp,
          isStreaming: true
        })
      } else {
        // æ‹¼æ¥åˆ°ç°æœ‰å›å¤
        this.currentStreamingMessage.content += replyText
        
        // æ›´æ–°æµå¼æ˜¾ç¤º
        this.onStreamingMessage?.({
          type: 'ai',
          content: this.currentStreamingMessage.content,
          timestamp: this.currentStreamingMessage.timestamp,
          isStreaming: true
        })
      }
      
      // é‡ç½®å®Œæˆå®šæ—¶å™¨
      if (this.streamingTimer) {
        clearTimeout(this.streamingTimer)
      }
      
      // è®¾ç½®å®Œæˆå®šæ—¶å™¨ï¼ˆ500mså†…æ²¡æœ‰æ–°ç‰‡æ®µåˆ™è®¤ä¸ºå®Œæˆï¼‰
      this.streamingTimer = setTimeout(() => {
        if (this.currentStreamingMessage) {
          console.log('ğŸ¤– AIå›å¤å®Œæˆ:', this.currentStreamingMessage.content)
          
          // å‘é€æœ€ç»ˆå®Œæ•´æ¶ˆæ¯
          this.onMessage?.({
            type: 'ai',
            content: this.currentStreamingMessage.content,
            timestamp: this.currentStreamingMessage.timestamp
          })
          
          // æ ‡è®°æµå¼æ˜¾ç¤ºå®Œæˆ
          this.onStreamingMessage?.({
            type: 'ai',
            content: this.currentStreamingMessage.content,
            timestamp: this.currentStreamingMessage.timestamp,
            isStreaming: false
          })
          
          // æ¸…ç†æµå¼çŠ¶æ€
          this.currentStreamingMessage = null
          this.streamingTimer = null
          
          // é‡ç½®VADçŠ¶æ€ï¼Œä½†ç»§ç»­ä¿æŒå½•éŸ³è¿æ¥
          this.resetVADState()
          console.log('ğŸ¤– AIå›å¤å®Œæˆï¼ŒVADçŠ¶æ€å·²é‡ç½®ï¼Œç»§ç»­å½•éŸ³')
        }
      }, 500)
    } else if (message.startsWith('AUDIO:')) {
      // TTSéŸ³é¢‘æ•°æ® (Base64æ ¼å¼)
      const audioContent = message.substring(6) // å»æ‰"AUDIO:"å‰ç¼€
      try {
        const audioData = atob(audioContent)
        const audioArray = new Uint8Array(audioData.length)
        for (let i = 0; i < audioData.length; i++) {
          audioArray[i] = audioData.charCodeAt(i)
        }
        console.log('âœ… Base64è§£ç æˆåŠŸ')
        this.playbackQueue.push(audioArray.buffer)
        this.processPlaybackQueue()
      } catch (error) {
        console.error('âŒ Base64è§£ç å¤±è´¥:', error)
      }
    } else if (message.startsWith('PARTIAL:')) {
      // å¤„ç†partial ASRç»“æœ
      const partialText = message.substring(8) // å»æ‰"PARTIAL:"å‰ç¼€
      console.log('ğŸ¤ å¤„ç†ASRéƒ¨åˆ†ç»“æœ:', partialText)
      
      // æ›´æ–°å½“å‰å¥å­å’Œä¸Šæ¬¡ç»“æœ
      this.lastPartialResult = partialText
      this.currentSentence = partialText
      
      // è°ƒç”¨å›è°ƒæ˜¾ç¤ºå®æ—¶ç»“æœ
      this.onAsrPartial?.(partialText)
      
    } else if (message.startsWith('FINAL:')) {
      // å¤„ç†final ASRç»“æœ
      const finalText = message.substring(6) // å»æ‰"FINAL:"å‰ç¼€
      console.log('ğŸ¤ å¤„ç†ASRæœ€ç»ˆç»“æœ:', finalText)
      
      // æ¸…ç©ºå®æ—¶æ˜¾ç¤º
      this.onAsrFinal?.(finalText)
      
      // æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ï¼ˆåªæœ‰éç©ºçš„æœ€ç»ˆç»“æœæ‰æ·»åŠ ï¼‰
      if (finalText.trim()) {
        this.onMessage?.({
          type: 'user',
          content: finalText,
          timestamp: Date.now()
        })
      }
    } else {
      // å°è¯•è§£æJSONæ¶ˆæ¯ï¼ˆç”¨äºæ§åˆ¶æ¶ˆæ¯ï¼‰
      try {
        const data = JSON.parse(message)
        console.log('ğŸ“‹ JSONæ§åˆ¶æ¶ˆæ¯:', data)
        
        if (data.type === 'asr_result') {
          this.onMessage?.({
            type: 'user',
            content: data.text,
            timestamp: Date.now()
          })
        } else if (data.type === 'ai_response') {
          this.onMessage?.({
            type: 'ai',
            content: data.text,
            timestamp: Date.now()
          })
          this.resetVADState()
        }
      } catch (jsonError) {
        // ä¸æ˜¯JSONæ ¼å¼ï¼Œå½“ä½œæ™®é€šASRè¯†åˆ«æ–‡æœ¬å¤„ç†ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
        console.log('ğŸ¤ å¤„ç†ASRè¯†åˆ«ï¼ˆå…¼å®¹æ ¼å¼ï¼‰:', message)
        this.onMessage?.({
          type: 'user',
          content: message,
          timestamp: Date.now()
        })
      }
    }
  }

  private async processPlaybackQueue(): Promise<void> {
    if (this.isPlaying || this.playbackQueue.length === 0) return

    this.isPlaying = true
    console.log('ğŸ”Š å¼€å§‹æ’­æ”¾TTSéŸ³é¢‘é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—é•¿åº¦:', this.playbackQueue.length)

    try {
      while (this.playbackQueue.length > 0) {
        const audioData = this.playbackQueue.shift()!
        await this.playAudio(audioData)
      }
    } finally {
      this.isPlaying = false
      console.log('ğŸ”Š TTSéŸ³é¢‘æ’­æ”¾å®Œæˆ')
    }
  }

  private async playAudio(audioData: ArrayBuffer): Promise<void> {
    return new Promise((resolve, reject) => {
      try {
        // æ£€æŸ¥éŸ³é¢‘æ•°æ®å¤§å°
        if (audioData.byteLength === 0) {
          console.warn('âš ï¸ æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®ï¼Œè·³è¿‡æ’­æ”¾')
          resolve()
          return
        }

        // æ£€æŸ¥éŸ³é¢‘æ•°æ®æ ¼å¼
        const uint8Array = new Uint8Array(audioData)
        const isWAV = uint8Array[0] === 0x52 && uint8Array[1] === 0x49 && uint8Array[2] === 0x46 && uint8Array[3] === 0x46
        const isMP3 = uint8Array[0] === 0xFF && (uint8Array[1] & 0xE0) === 0xE0
        const isOGG = uint8Array[0] === 0x4F && uint8Array[1] === 0x67 && uint8Array[2] === 0x67 && uint8Array[3] === 0x53

        let processedAudioData = audioData

        // å¦‚æœä¸æ˜¯æ ‡å‡†éŸ³é¢‘æ ¼å¼ï¼Œå‡è®¾æ˜¯PCMæ•°æ®å¹¶è½¬æ¢ä¸ºWAV
        if (!isWAV && !isMP3 && !isOGG) {
          console.log('ğŸ”§ æ£€æµ‹åˆ°PCMæ•°æ®ï¼Œè½¬æ¢ä¸ºWAVæ ¼å¼')
          processedAudioData = this.convertPcmToWav(audioData)
        }

        const audioContext = new AudioContext()
        
        audioContext.decodeAudioData(processedAudioData.slice(0))
          .then(audioBuffer => {
            console.log('ğŸ”Š æ’­æ”¾TTSéŸ³é¢‘ç‰‡æ®µ:', audioBuffer.duration.toFixed(2), 'ç§’')
            const source = audioContext.createBufferSource()
            source.buffer = audioBuffer
            source.connect(audioContext.destination)
            
            source.onended = () => {
              audioContext.close()
              resolve()
            }
            
            source.start()
          })
          .catch(error => {
            console.error('âŒ Web Audio APIè§£ç å¤±è´¥:', error)
            audioContext.close()
            // å°è¯•ä½¿ç”¨Audioå…ƒç´ ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            this.playAudioWithAudioElement(processedAudioData).then(resolve).catch(reject)
          })
      } catch (error) {
        console.error('âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥:', error)
        reject(error)
      }
    })
  }

  // PCMè½¬WAVæ ¼å¼
  private convertPcmToWav(pcmData: ArrayBuffer): ArrayBuffer {
    const pcmArray = new Int16Array(pcmData)
    const sampleRate = 16000
    const numChannels = 1
    const bitsPerSample = 16
    
    const wavHeaderLength = 44
    const wavBuffer = new ArrayBuffer(wavHeaderLength + pcmData.byteLength)
    const view = new DataView(wavBuffer)
    
    // WAVæ–‡ä»¶å¤´
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i))
      }
    }
    
    writeString(0, 'RIFF')
    view.setUint32(4, wavBuffer.byteLength - 8, true)
    writeString(8, 'WAVE')
    writeString(12, 'fmt ')
    view.setUint32(16, 16, true) // fmt chunk size
    view.setUint16(20, 1, true) // PCM format
    view.setUint16(22, numChannels, true)
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true) // byte rate
    view.setUint16(32, numChannels * bitsPerSample / 8, true) // block align
    view.setUint16(34, bitsPerSample, true)
    writeString(36, 'data')
    view.setUint32(40, pcmData.byteLength, true)
    
    // å¤åˆ¶PCMæ•°æ®
    const wavArray = new Int16Array(wavBuffer, wavHeaderLength)
    wavArray.set(pcmArray)
    
    console.log('ğŸ”§ PCMè½¬WAVå®Œæˆ:', {
      åŸå§‹å¤§å°: pcmData.byteLength,
      WAVå¤§å°: wavBuffer.byteLength,
      é‡‡æ ·ç‡: sampleRate,
      å£°é“æ•°: numChannels
    })
    
    return wavBuffer
  }

  // å¤‡é€‰éŸ³é¢‘æ’­æ”¾æ–¹æ³•
  private async playAudioWithAudioElement(audioData: ArrayBuffer): Promise<void> {
    return new Promise((resolve, reject) => {
      try {
        const blob = new Blob([audioData], { type: 'audio/wav' })
        const audioUrl = URL.createObjectURL(blob)
        const audio = new Audio(audioUrl)
        
        audio.onended = () => {
          URL.revokeObjectURL(audioUrl)
          console.log('ğŸ”Š Audioå…ƒç´ æ’­æ”¾å®Œæˆ')
          resolve()
        }
        
        audio.onerror = (error) => {
          URL.revokeObjectURL(audioUrl)
          console.error('âŒ Audioå…ƒç´ æ’­æ”¾å¤±è´¥:', error)
          reject(error)
        }
        
        audio.play().catch(error => {
          URL.revokeObjectURL(audioUrl)
          console.error('âŒ Audioå…ƒç´ æ’­æ”¾å¯åŠ¨å¤±è´¥:', error)
          reject(error)
        })
      } catch (error) {
        console.error('âŒ åˆ›å»ºAudioå…ƒç´ å¤±è´¥:', error)
        reject(error)
      }
    })
  }

  // è·å–è¿æ¥çŠ¶æ€
  getConnectionStatus(): boolean {
    return this.isConnected
  }

  // è·å–å½•éŸ³çŠ¶æ€
  getRecordingStatus(): boolean {
    return this.isRecording
  }

  // è·å–ç»Ÿè®¡ä¿¡æ¯
  getStats() {
    return {
      frameCount: this.frameCount,
      silentFrameCount: this.silentFrameCount,
      speechFrameCount: this.speechFrameCount,
      vadState: this.vadState,
      currentVolume: this.currentVolume
    }
  }
}

export default new VoiceChatService()